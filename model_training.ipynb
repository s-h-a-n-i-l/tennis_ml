{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75ece50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f9c20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_training_dataframe(parquet_root: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Load and prepare parquet files for model training.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parquet_root:\n",
    "        Directory containing parquet files. All parquet files found recursively\n",
    "        under this directory are concatenated into a single DataFrame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Data ready for XGBoost. Rows with missing values are dropped and\n",
    "        columns are converted to integer or boolean types where appropriate.\n",
    "    \"\"\"\n",
    "\n",
    "    parquet_root = Path(parquet_root)\n",
    "    files = sorted(parquet_root.rglob(\"*.parquet\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No parquet files found under {parquet_root}\")\n",
    "\n",
    "    # Read all parquet files and concatenate\n",
    "    frames = [pd.read_parquet(f, engine=\"pyarrow\") for f in files]\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # Drop any rows containing NA values\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Convert object columns to numeric or categorical codes\n",
    "    obj_cols = df.select_dtypes(include=\"object\").columns \n",
    "    obj_cols = obj_cols.drop(\"match_id\")\n",
    "    for col in obj_cols:\n",
    "        lower = df[col].str.lower()\n",
    "        if set(lower.unique()) <= {\"true\", \"false\"}:\n",
    "            df[col] = lower == \"true\"\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\").cat.codes\n",
    "\n",
    "    # Convert numeric columns to int or bool where possible\n",
    "    num_cols = df.select_dtypes(include=\"number\").columns\n",
    "    for col in num_cols:\n",
    "        series = df[col]\n",
    "        if pd.api.types.is_float_dtype(series) and np.allclose(series, series.astype(int)):\n",
    "            series = series.astype(int)\n",
    "        if set(series.unique()) <= {0, 1}:\n",
    "            series = series.astype(bool)\n",
    "        else:\n",
    "            series = pd.to_numeric(series, downcast=\"integer\")\n",
    "        df[col] = series\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d893a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_training_dataframe(\"data/matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23d398ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = data['match_id'].unique()\n",
    "feature_cols = [c for c in data.columns if c not in ('match_id', 'y_match')]\n",
    "train_ids = set(np.random.choice(matches, size=int(0.8*len(matches)), replace=False))\n",
    "train_data = data[data['match_id'].isin(train_ids)]\n",
    "test_data  = data[~data['match_id'].isin(train_ids)]\n",
    "X_train, y_train = train_data[feature_cols], train_data['y_match']\n",
    "X_test,  y_test  = test_data[feature_cols],  test_data['y_match']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c522fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    objective=\"binary:logistic\",  # outputs a probability for class 1\n",
    "    eval_metric=\"logloss\",        # train-time metric; good for probability models\n",
    "    max_depth=50,                  # tree depth (controls complexity)\n",
    "    learning_rate=0.1,            # step size for boosting\n",
    "    n_estimators=1000,             # number of trees\n",
    "    early_stopping_rounds=25,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tennis-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
